---
title: "Assembly Comparison of Simulated and RenSeq Baits Enriched Illumina and PacBio Reads" 
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## RenSeq Enriched Gel Image Analysis for Intensity

A gel image of RenSeq baits enriched DNA fragments is obtained. For intensity analysis of the enriched DNA fragments, the image is cropped so that only the DNA fragments of interested are captured.

The python code for cropping the DNA fragments of interests is below:

```{python, engine.path='/usr/bin/python3'}

from matplotlib import pyplot as plt
import pandas as pd
import numpy as np
from PIL import Image
import PIL.ImageOps
import random
import decimal
import json

img = Image.open('enriched_long.tif')
imgCropped = img.crop((890,180, 990, 212))  # cropping 3.5kb to 6kb
plt.imshow(np.asarray(imgCropped), cmap="gray")
```

In understand in basic way, an image is a table of pixels in rows and columns. The intensity data can be obtained from each pixel of an image. For our purpose, an intensity of each pixel in a row is obtained and a mean intensity is calculated. This is done for every row of pixels from top to bottom of the cropped image. Then a sum of mean intensities is calculated which is then used to get the propertion of intensity in each row of pixels in the cropped image. From the porportion of intensities, the cumulative proportion of intensity is obtained from top to the bottom of the cropped image.

The python code for the above process is:
```{python, engine.path='/usr/bin/python3'}
data = np.array(imgCropped, dtype="float64")   # data is a two-dimensional array

graph_intensities = []
intensities = []
cum_proportion = []
intensities=data.mean(axis=1) # get mean by column (axis=1), to get mean by row(axis=0). This is same as doing the for loop below commented
json_intensities=dict()
for data in range(len(intensities)):
    #intensities.append(a.mean())
    json_intensities[str(data)]=intensities[data]

print(json_intensities)

with open("intensities.json", "wt") as jsondata:
    json.dump(json_intensities, jsondata, sort_keys=True, indent=4, separators=(',', ': '))

# get intensities, cumulative intensiteis and cumulative proportions
print("Intensities:")
print(",".join([str(x) for x in intensities[:3]]), "..." , ",".join([str(x) for x in intensities[-3:]]))
total_intensity=sum(intensities)
#print("Total intensity ", total_intensity)
cum_intensities=np.cumsum(intensities)
#print("Cum intensity ", cum_intensities)
proportions=[x/total_intensity for x in intensities]
#print("Proportions", proportions)
cum_proportions=np.cumsum(proportions)
#print("Cum Proportions", cum_proportions)

print("\n\nCumulatative Intensities: ")
print(",".join([str(x) for x in cum_proportions[:3]]),"...", ",".join([str(x) for x in cum_proportions[-3:]]))


max_proportion=max(cum_proportions)
min_proportion=min(cum_proportions)

#Plot intensities, cumulative intensiteis and cumulative proportions
plt.figure()
plt.title("Intensities")
plt.plot(intensities)
plt.savefig('results/Intensities.png')
plt.show()


plt.figure()
plt.title("Cumulative Intensities")
plt.plot(cum_intensities)
plt.savefig('results/cum_intensities.png')
plt.show()

plt.figure()
plt.title("Cumulative Proportions")
plt.plot(cum_proportions)
plt.savefig('results/cum_proportions.png')
plt.show()

```

Showing the figures:

```{r, echo=FALSE}
knitr::include_graphics('results/Intensities.png')
```

At this stage, we would want to know the sequence lengths of the DNA fragments in the cropped image. The image of cumulative proportion of intensities (above) shows there are 32 units/rows of intesnsities. As the image is cropped to get the DNA fragments from 3.5 kb to 6 kb, the length of bases per unit/row, can be calculated as 
```{python, engine.path='/usr/bin/python3'}
unitlength=(6000 - 3500)/32
```

The sequence length decreases from the top to the bottom of the image. This is because smaller DNA fragments move faster through the gel and therefore are at the bottom of the gel.

## Generating Random Sequence Lengths

Now, we know the sequence length at each row of intensities in the cropped image, random sequence lengths can be generated by generating random numbers between 0 and 1 and then converting the those numbers to the reciprocal number between the highest (here 6 kb) and lowest (here 3.5 kb) intensities in the cropped image. To understand this in easy terms, a random number 0 would mean a sequence length of 3.5kb, 1 would mean 6 kb and 0.5 would mean 6000 - (6000 - 3500)/2=4750

The python code to generate random numbers is:
```{python, engine.path='/usr/bin/python3'}
#generate 100,000 random values in normal distribution

num_of_seqs=100000

## generate random values in normal distribution
np.random.seed(19680801) ## seed value for reproducibility
mu, sigma = 0.5, 0.15
random_values = mu + sigma * np.random.randn(100000)

# the histogram of the data
plt.hist(random_values, 50)

plt.xlabel('Random values')
plt.ylabel('Frequency')
plt.title('Histogram of ' + str(num_of_seqs) + ' Random Values')
plt.axis([0,1,0, 7000])
plt.grid(True)
plt.text(0.2,6000, r'Binsize=50')
plt.savefig('results/random_numbers_normal_distribution.png')
plt.show()
```

Code for translating the random values to the reciprocal sequence lengths between 3.5 kb to 6 kb 
```{python, engine.path='/usr/bin/python3'}
# get each point in x-axis in the plot 
unitlength = (6000 - 3500)/32

#print("Each point base pairs: ", unitlength)
# count=0
# for count in range(num_of_seqs):
#     randomvalue=float(random.random())
#     if randomvalue >= min_proportion and randomvalue <=max_proportion:
#         random_values.append(randomvalue)
#         count+=1
        
## convert the random values to sequence lengths
seq_lengths=[round(6000 - x*32*unitlength, 0) for x in random_values]
#print(",".join([str(x) for x in random_values[:3]]), "..." , ",".join([str(x) for x in random_values[-3:]]))
#print(",".join([str(x) for x in seq_lengths[:3]]), "..." , ",".join([str(x) for x in seq_lengths[-3:]]))


## get seq length data into array 
seq_length_data=dict()
for data in range(len(seq_lengths)):
    seq_length_data[str(data)]=seq_lengths[data]

#print(seq_length_data)

## save sequence lengths as json in a file
with open("results/seq_lengths.json", "wt") as seqlengthjson:
    json.dump(seq_length_data, seqlengthjson, sort_keys=True, indent=4, separators=(',', ': '))

seq_lengths=np.array(seq_lengths)
fig=plt.figure(figsize=(20,30))
plt.title("Randomly Generated Enriched Sequence Lengths", fontsize=40)
plt.xlabel("simulated Sequence Lengths", fontsize=32)
plt.ylabel("Frequency", fontsize=32)
plt.tick_params(which='both', labelsize=32.00)
plt.hist(seq_lengths, 50)
plt.text(4000, 6000, r'BinSize=50', fontsize=30)
plt.axis([3000,6000, 0, 7000])
plt.grid(True)
plt.savefig('results/random_sequences_normal_distribution.png')
plt.show()
```


## Generating random sequences from a reference sequence using random sequences lengths

Since, we have random sequence lengths from code above, subsequences of these lengths can be picked out randomly from a given reference sequence. A reference sequence, in FASTA format, generally has multiple sequences. A completed reference sequence has FASTA file with sequences as chromosomal sequences. An incomplete refernce seqeunce has contig/scaffold sequences.

While picking out random subsequences from 
